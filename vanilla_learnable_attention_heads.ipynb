{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "from torchmetrics.classification import AveragePrecision, MulticlassAccuracy, MulticlassF1Score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ntm.encapsulated import EncapsulatedNTM\n",
    "from config import configuration as configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "devanagari_alphabets = [\n",
    "    \"अ\", \"आ\", \"इ\", \"ई\", \"उ\", \"ऊ\", \"ऋ\", \"ए\", \"ऐ\", \"ओ\", \"औ\",\n",
    "    \"क\", \"ख\", \"ग\", \"घ\", \"ङ\", \"च\", \"छ\", \"ज\", \"झ\", \"ञ\", \"ट\",\n",
    "    \"ठ\", \"ड\", \"ढ\", \"ण\", \"त\", \"थ\", \"द\", \"ध\", \"न\", \"प\", \"फ\",\n",
    "    \"ब\", \"भ\", \"म\", \"य\", \"र\", \"ल\", \"व\", \"श\", \"ष\", \"स\", \"ह\"\n",
    "]\n",
    "\n",
    "char_map = {idx: char for idx, char in enumerate(devanagari_alphabets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\envs_win\\torch\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, input_channels: int, out_channels: int, kernel_size: tuple = (3, 3)):\n",
    "        \"\"\"Basic Conv Block with convolution layer, etc.\n",
    "\n",
    "        Args:\n",
    "            input_channels (int): _description_\n",
    "            out_channels (int): _description_\n",
    "            kernel_size (tuple, optional): _description_. Defaults to (3, 3).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.conv = nn.Conv2d(self.input_channels, self.out_channels, self.kernel_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(self.kernel_size)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.batchnorm = nn.BatchNorm2d(self.out_channels)\n",
    "    \n",
    "    def forward(self, x, training:bool = True):\n",
    "        conv_res = self.conv(x)\n",
    "        activated = self.relu(conv_res)\n",
    "        pooled = self.maxpool(activated)\n",
    "        if training:\n",
    "            pooled = self.dropout(pooled)\n",
    "        y = self.batchnorm(pooled)\n",
    "        return y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"ConvBlock({self.input_channels, self.out_channels, self.kernel_size})\"\n",
    "\n",
    "\n",
    "class FeedforwardController(nn.Module):\n",
    "    def __init__(self, num_inputs:int, num_layers:int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        # self.num_outputs = num_outputs\n",
    "        self.num_layers = num_layers\n",
    "        # self.batch_size = batch_size\n",
    "        self.device_ = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model_ = nn.Sequential(\n",
    "            ConvBlock(self.num_inputs, 32, (2,2)),\n",
    "            ConvBlock(32, 64, (2,2))\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x, training:bool=True):\n",
    "        y = self.model_(x)\n",
    "\n",
    "        return self.flatten(y)\n",
    "\n",
    "num_inputs = 1\n",
    "num_outputs = 44\n",
    "controller_size = 3136 #1024     3136 for FeedforwardController in the cell above 12800 for feedforwardcontroller with \n",
    "controller_layers = 1\n",
    "num_heads = 4\n",
    "num_classes = 44\n",
    "N, M = 10, 10\n",
    "controller_ = FeedforwardController\n",
    "num_epochs = 5\n",
    "\n",
    "batch_size = 2 #220\n",
    "\n",
    "# defining the network\n",
    "net = EncapsulatedNTM(\n",
    "    num_inputs,\n",
    "    num_outputs,\n",
    "    controller_size,\n",
    "    controller_layers,\n",
    "    num_heads,\n",
    "    N,\n",
    "    M,\n",
    "    controller_= controller_, #FeedforwardController,\n",
    "    vanilla_heads=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annotations_file, img_dir):\n",
    "        self.images_csv = annotations_file.reset_index(drop=True) #pd.read_csv(annotations_file).reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        # self.transforms_ = tv.transforms.Compose([\n",
    "        #     tv.transforms.Resize(40),\n",
    "        #     # tv.transforms.CenterCrop(40),\n",
    "        #     tv.transforms.ConvertImageDtype(torch.float),\n",
    "        #     tv.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        # ])\n",
    "        \n",
    "    def transforms_(self, image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if image.ndim == 3 else image\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10)\n",
    "        # normed= cv2.normalize(thresh, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        skeleton = cv2.ximgproc.thinning(thresh, None, 1)\n",
    "        image = cv2.resize(skeleton, (32, 32))\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_csv)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.images_csv.iloc[index, 0])\n",
    "        # image = tv.io.image.read_image(img_path)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        image_ = self.transforms_(image) #.to(device_)\n",
    "        image = torch.from_numpy(image_)\n",
    "        label = self.images_csv.iloc[index, 1]\n",
    "        label = torch.nn.functional.one_hot(torch.tensor(label).to(torch.int64), num_classes=num_outputs)\n",
    "        return image.unsqueeze(0), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = configs()\n",
    "\n",
    "PATH_PRINTED_TRAIN_CSV, PATH_PRINTED_TRAIN_IMGS = Config.paths(printed=True, train=True)\n",
    "PATH_PRINTED_VAL_CSV, PATH_PRINTED_VAL_IMGS = Config.paths(printed=True, train=False)\n",
    "\n",
    "PATH_HW_TRAIN_CSV, PATH_HW_TRAIN_IMGS = Config.paths(printed=False, train=True)\n",
    "PATH_HW_VAL_CSV, PATH_HW_VAL_IMGS = Config.paths(printed=False, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset(pd.read_csv(PATH_PRINTED_TRAIN_CSV), PATH_PRINTED_TRAIN_IMGS)\n",
    "val_dataset = dataset(pd.read_csv(PATH_PRINTED_VAL_CSV), PATH_PRINTED_VAL_IMGS)\n",
    "\n",
    "# creating dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for handwritten\n",
    "\n",
    "train_dataset = dataset(pd.read_csv(PATH_HW_TRAIN_CSV), PATH_HW_TRAIN_IMGS)\n",
    "val_dataset = dataset(pd.read_csv(PATH_HW_VAL_CSV), PATH_HW_VAL_IMGS)\n",
    "\n",
    "# creating dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "# metric\n",
    "# metric = AveragePrecision(task=\"multiclass\", num_classes=num_outputs)\n",
    "metric = MulticlassAccuracy(num_classes=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncapsulatedNTM(\n",
       "  (ntm): Controller: FeedforwardController(\n",
       "    (model_): Sequential(\n",
       "      (0): ConvBlock((1, 32, (2, 2)))\n",
       "      (1): ConvBlock((32, 64, (2, 2)))\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  ), Num of Inputs: 1, Num of Outputs: 44, Memory: NTMMemory()\n",
       "  (memory): NTMMemory()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_ = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.train().to(device_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\self\\thesis\\win_ntm\\humanlike-ocr\\ntm\\ntm.py:105: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(o), self.state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.029, train acc 0.323\n",
      "Loss train 0.029,  validation 0.162,  val acc 0.053\n",
      "Epoch 1\n",
      "epoch 1, loss 0.001, train acc 0.464\n",
      "Loss train 0.001,  validation 0.159,  val acc 0.072\n",
      "Epoch 2\n",
      "epoch 2, loss 0.003, train acc 0.516\n",
      "Loss train 0.003,  validation 0.176,  val acc 0.084\n",
      "Epoch 3\n",
      "epoch 3, loss 0.001, train acc 0.545\n",
      "Loss train 0.001,  validation 0.194,  val acc 0.105\n",
      "Epoch 4\n",
      "epoch 4, loss 0.005, train acc 0.554\n",
      "Loss train 0.005,  validation 0.224,  val acc 0.111\n",
      "Epoch 5\n",
      "epoch 5, loss 0.000, train acc 0.570\n",
      "Loss train 0.000,  validation 0.247,  val acc 0.121\n",
      "Epoch 6\n",
      "epoch 6, loss 0.000, train acc 0.590\n",
      "Loss train 0.000,  validation 0.231,  val acc 0.136\n",
      "Epoch 7\n",
      "epoch 7, loss 0.000, train acc 0.618\n",
      "Loss train 0.000,  validation 0.233,  val acc 0.136\n",
      "Epoch 8\n",
      "epoch 8, loss 0.000, train acc 0.649\n",
      "Loss train 0.000,  validation 0.235,  val acc 0.159\n",
      "Epoch 9\n",
      "epoch 9, loss 0.004, train acc 0.662\n",
      "Loss train 0.004,  validation 0.248,  val acc 0.156\n",
      "Epoch 10\n",
      "epoch 10, loss 0.000, train acc 0.674\n",
      "Loss train 0.000,  validation 0.208,  val acc 0.173\n",
      "Epoch 11\n",
      "epoch 11, loss 0.000, train acc 0.677\n",
      "Loss train 0.000,  validation 0.244,  val acc 0.152\n",
      "Epoch 12\n",
      "epoch 12, loss 0.000, train acc 0.692\n",
      "Loss train 0.000,  validation 0.251,  val acc 0.164\n",
      "Epoch 13\n",
      "epoch 13, loss 0.000, train acc 0.691\n",
      "Loss train 0.000,  validation 0.258,  val acc 0.179\n",
      "Epoch 14\n",
      "epoch 14, loss 0.000, train acc 0.704\n",
      "Loss train 0.000,  validation 0.257,  val acc 0.170\n",
      "Epoch 15\n",
      "epoch 15, loss 0.000, train acc 0.707\n",
      "Loss train 0.000,  validation 0.289,  val acc 0.155\n",
      "Epoch 16\n",
      "epoch 16, loss 0.000, train acc 0.710\n",
      "Loss train 0.000,  validation 0.308,  val acc 0.159\n",
      "Epoch 17\n",
      "epoch 17, loss 0.000, train acc 0.714\n",
      "Loss train 0.000,  validation 0.357,  val acc 0.147\n",
      "Epoch 18\n",
      "epoch 18, loss 0.000, train acc 0.712\n",
      "Loss train 0.000,  validation 0.335,  val acc 0.161\n",
      "Epoch 19\n",
      "epoch 19, loss 0.000, train acc 0.714\n",
      "Loss train 0.000,  validation 0.345,  val acc 0.156\n",
      "Epoch 20\n",
      "epoch 20, loss 0.000, train acc 0.718\n",
      "Loss train 0.000,  validation 0.375,  val acc 0.154\n",
      "Epoch 21\n",
      "epoch 21, loss 0.000, train acc 0.718\n",
      "Loss train 0.000,  validation 0.450,  val acc 0.133\n",
      "Epoch 22\n",
      "epoch 22, loss 0.000, train acc 0.716\n",
      "Loss train 0.000,  validation 0.386,  val acc 0.155\n",
      "Epoch 23\n",
      "epoch 23, loss 0.000, train acc 0.718\n",
      "Loss train 0.000,  validation 0.442,  val acc 0.141\n",
      "Epoch 24\n",
      "epoch 24, loss 0.000, train acc 0.717\n",
      "Loss train 0.000,  validation 0.411,  val acc 0.160\n",
      "Epoch 25\n",
      "epoch 25, loss 0.000, train acc 0.722\n",
      "Loss train 0.000,  validation 0.413,  val acc 0.158\n",
      "Epoch 26\n",
      "epoch 26, loss 0.000, train acc 0.722\n",
      "Loss train 0.000,  validation 0.460,  val acc 0.152\n",
      "Epoch 27\n",
      "epoch 27, loss 0.000, train acc 0.729\n",
      "Loss train 0.000,  validation 0.415,  val acc 0.154\n",
      "Epoch 28\n",
      "epoch 28, loss 0.000, train acc 0.727\n",
      "Loss train 0.000,  validation 0.467,  val acc 0.134\n",
      "Epoch 29\n",
      "epoch 29, loss 0.000, train acc 0.724\n",
      "Loss train 0.000,  validation 0.420,  val acc 0.150\n",
      "Epoch 30\n",
      "epoch 30, loss 0.000, train acc 0.725\n",
      "Loss train 0.000,  validation 0.409,  val acc 0.157\n",
      "Epoch 31\n",
      "epoch 31, loss 0.000, train acc 0.720\n",
      "Loss train 0.000,  validation 0.407,  val acc 0.167\n",
      "Epoch 32\n",
      "epoch 32, loss 0.000, train acc 0.718\n",
      "Loss train 0.000,  validation 0.353,  val acc 0.183\n",
      "Epoch 33\n",
      "epoch 33, loss 0.000, train acc 0.716\n",
      "Loss train 0.000,  validation 0.403,  val acc 0.166\n",
      "Epoch 34\n",
      "epoch 34, loss 0.000, train acc 0.722\n",
      "Loss train 0.000,  validation 0.407,  val acc 0.177\n",
      "Epoch 35\n",
      "epoch 35, loss 0.000, train acc 0.723\n",
      "Loss train 0.000,  validation 0.412,  val acc 0.170\n",
      "Epoch 36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m list_labels\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39margmax(labels, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     37\u001b[0m \u001b[39m# avg_prec = metric(outputs, torch.argmax(labels, dim=1))\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39m# print(torch.argmax(outputs, dim=1), torch.argmax(labels, dim=1))\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m avg_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     41\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     43\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m avg_loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\work\\envs_win\\torch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32md:\\work\\envs_win\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "\n",
    "# training loop\n",
    "vanilla_attention_heads_train_loss = []\n",
    "vanilla_attention_heads_train_acc = []\n",
    "vanilla_attention_heads_val_loss = []\n",
    "vanilla_attention_heads_val_acc = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "    last_loss = 0.0\n",
    "    list_outputs = []\n",
    "    list_labels = []\n",
    "    \n",
    "    net.train(True)\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        inputs, labels = data[0].to(device_), data[1].to(device_)\n",
    "        # print(inputs.size())\n",
    "        labels = labels.type(torch.float)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        net.init_sequence(batch_size)\n",
    "\n",
    "\n",
    "        training = True\n",
    "        outputs, _ = net(inputs)\n",
    "        avg_loss = loss_fn(outputs, labels)\n",
    "\n",
    "        list_outputs.append(outputs)\n",
    "        list_labels.append(torch.argmax(labels, dim=1))\n",
    "        \n",
    "        # avg_prec = metric(outputs, torch.argmax(labels, dim=1))\n",
    "        # print(torch.argmax(outputs, dim=1), torch.argmax(labels, dim=1))\n",
    "        avg_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += avg_loss.item()\n",
    "        last_loss = running_loss\n",
    "        # last_avg_prec = avg_prec\n",
    "\n",
    "        # appending the train loss for grpah plotting\n",
    "        vanilla_attention_heads_train_loss.append(avg_loss.item())\n",
    "\n",
    "    outputs = torch.cat(list_outputs, dim=0)\n",
    "    labels = torch.cat(list_labels).squeeze()\n",
    "    # print(labels)\n",
    "    # print(torch.argmax(outputs, dim=1))\n",
    "    acc = metric(outputs, labels)\n",
    "\n",
    "    # adding for the graph \n",
    "    vanilla_attention_heads_train_acc.append(acc)\n",
    "\n",
    "    print(\"epoch {}, loss {:.3f}, train acc {:.3f}\".format(epoch, last_loss, acc))\n",
    "    # model_scripted = torch.jit.script(net)\n",
    "    # torch.save(net.state_dict(), \"model_state_convnet_01-06-23_.pt\")\n",
    "    # torch.save(net, \"model_convnet_{}_{}.pt\".format(\"12-05-23\", epoch))\n",
    "    \n",
    "    # validation\n",
    "    list_outputs = []\n",
    "    list_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_vloss = 0.0\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            net.init_sequence(batch_size)\n",
    "\n",
    "            vinputs, vlabels = data[0].to(device_), data[1].to(device_)\n",
    "            vlabels = vlabels.type(torch.float)\n",
    "            voutputs, _ = net(vinputs)\n",
    "            list_outputs.append(voutputs)\n",
    "            list_labels.append(torch.argmax(vlabels, dim=1))\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "            # appending the val loss for the graph plotting\n",
    "            vanilla_attention_heads_val_loss.append(vloss.item())\n",
    "\n",
    "        voutputs = torch.cat(list_outputs, dim=0)\n",
    "        vlabels = torch.cat(list_labels).squeeze()\n",
    "        vacc = metric(voutputs, vlabels)\n",
    "        \n",
    "        # appending the val accuracy for plotting graph\n",
    "        vanilla_attention_heads_val_acc.append(vacc)\n",
    "\n",
    "        avg_vloss = running_vloss / (i+1)\n",
    "        print(\"Loss train {:.3f},  validation {:.3f},  val acc {:.3f}\".format(avg_loss, avg_vloss, vacc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\envs_win\\torch\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# defining the network\n",
    "net = EncapsulatedNTM(\n",
    "    num_inputs,\n",
    "    num_outputs,\n",
    "    controller_size,\n",
    "    controller_layers,\n",
    "    num_heads,\n",
    "    N,\n",
    "    M,\n",
    "    controller_= controller_, #FeedforwardController,\n",
    "    vanilla_heads=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "epoch 0, loss 0.122, train acc 0.021\n",
      "Loss train 0.122,  validation 0.112,  val acc 0.024\n",
      "Epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m net\u001b[39m.\u001b[39minit_sequence(batch_size)\n\u001b[0;32m     30\u001b[0m training \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m outputs, _ \u001b[39m=\u001b[39m net(inputs)\n\u001b[0;32m     32\u001b[0m avg_loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m     34\u001b[0m list_outputs\u001b[39m.\u001b[39mappend(outputs)\n",
      "File \u001b[1;32md:\\work\\envs_win\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\work\\self\\thesis\\win_ntm\\humanlike-ocr\\ntm\\encapsulated.py:58\u001b[0m, in \u001b[0;36mEncapsulatedNTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_inputs, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     57\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m---> 58\u001b[0m o, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprevious_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mntm(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprevious_state)\n\u001b[0;32m     59\u001b[0m \u001b[39mreturn\u001b[39;00m o, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprevious_state\n",
      "File \u001b[1;32md:\\work\\envs_win\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\work\\self\\thesis\\win_ntm\\humanlike-ocr\\ntm\\ntm.py:91\u001b[0m, in \u001b[0;36mNTM.forward\u001b[1;34m(self, x, prev_state, training)\u001b[0m\n\u001b[0;32m     89\u001b[0m         reads \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [r]\n\u001b[0;32m     90\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m         head_state \u001b[39m=\u001b[39m head(controller_outp, prev_head_state)\n\u001b[0;32m     92\u001b[0m     heads_states \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [head_state]\n\u001b[0;32m     94\u001b[0m \u001b[39m# Generate Output \u001b[39;00m\n",
      "File \u001b[1;32md:\\work\\envs_win\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\work\\self\\thesis\\win_ntm\\humanlike-ocr\\ntm\\head.py:231\u001b[0m, in \u001b[0;36mNTMWriteHead.forward\u001b[1;34m(self, embeddings, w_prev)\u001b[0m\n\u001b[0;32m    225\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma_reg(mat) \n\u001b[0;32m    227\u001b[0m \u001b[39m# e should be in [0, 1] \u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[39m# e = torch.sigmoid(e)\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \n\u001b[0;32m    230\u001b[0m \u001b[39m# write to memory\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory\u001b[39m.\u001b[39;49maddress(k, beta, g, s, gamma, w_prev) \u001b[39m#self._address_memory(k, beta, g, s, gamma, w_prev)\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mwrite(w, e, a)\n\u001b[0;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m w\n",
      "File \u001b[1;32md:\\work\\self\\thesis\\win_ntm\\humanlike-ocr\\ntm\\memory.py:86\u001b[0m, in \u001b[0;36mNTMMemory.address\u001b[1;34m(self, k, beta, g, s, gamma, w_prev)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m# location focus\u001b[39;00m\n\u001b[0;32m     85\u001b[0m wg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpolate(w_prev, wc, g)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_)\n\u001b[1;32m---> 86\u001b[0m w_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shift(wg, s)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_)    \u001b[39m# convolutional shift\u001b[39;00m\n\u001b[0;32m     87\u001b[0m w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sharpen(w_hat, gamma)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_)\n\u001b[0;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m w\n",
      "File \u001b[1;32md:\\work\\self\\thesis\\win_ntm\\humanlike-ocr\\ntm\\memory.py:101\u001b[0m, in \u001b[0;36mNTMMemory._shift\u001b[1;34m(self, wg, s)\u001b[0m\n\u001b[0;32m     99\u001b[0m result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(wg\u001b[39m.\u001b[39msize())\n\u001b[0;32m    100\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size):\n\u001b[1;32m--> 101\u001b[0m     result[b] \u001b[39m=\u001b[39m _convolve(wg[b], s[b])\n\u001b[0;32m    102\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "\n",
    "# training loop\n",
    "modified_attention_heads_train_loss = []\n",
    "modified_attention_heads_train_acc = []\n",
    "modified_attention_heads_val_loss = []\n",
    "modified_attention_heads_val_acc = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "    last_loss = 0.0\n",
    "    list_outputs = []\n",
    "    list_labels = []\n",
    "    \n",
    "    net.train(True)\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        inputs, labels = data[0].to(device_), data[1].to(device_)\n",
    "        # print(inputs.size())\n",
    "        labels = labels.type(torch.float)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        net.init_sequence(batch_size)\n",
    "\n",
    "\n",
    "        training = True\n",
    "        outputs, _ = net(inputs)\n",
    "        avg_loss = loss_fn(outputs, labels)\n",
    "\n",
    "        list_outputs.append(outputs)\n",
    "        list_labels.append(torch.argmax(labels, dim=1))\n",
    "        \n",
    "        # avg_prec = metric(outputs, torch.argmax(labels, dim=1))\n",
    "        # print(torch.argmax(outputs, dim=1), torch.argmax(labels, dim=1))\n",
    "        avg_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += avg_loss.item()\n",
    "        last_loss = running_loss\n",
    "        # last_avg_prec = avg_prec\n",
    "\n",
    "        # appending the train loss for grpah plotting\n",
    "        modified_attention_heads_train_loss.append(avg_loss.item())\n",
    "\n",
    "    outputs = torch.cat(list_outputs, dim=0)\n",
    "    labels = torch.cat(list_labels).squeeze()\n",
    "    # print(labels)\n",
    "    # print(torch.argmax(outputs, dim=1))\n",
    "    acc = metric(outputs, labels)\n",
    "\n",
    "    # adding for the graph \n",
    "    modified_attention_heads_train_acc.append(acc)\n",
    "\n",
    "    print(\"epoch {}, loss {:.3f}, train acc {:.3f}\".format(epoch, last_loss, acc))\n",
    "    # model_scripted = torch.jit.script(net)\n",
    "    # torch.save(net.state_dict(), \"model_state_convnet_01-06-23_.pt\")\n",
    "    # torch.save(net, \"model_convnet_{}_{}.pt\".format(\"12-05-23\", epoch))\n",
    "    \n",
    "    # validation\n",
    "    list_outputs = []\n",
    "    list_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_vloss = 0.0\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            net.init_sequence(batch_size)\n",
    "\n",
    "            vinputs, vlabels = data[0].to(device_), data[1].to(device_)\n",
    "            vlabels = vlabels.type(torch.float)\n",
    "            voutputs, _ = net(vinputs)\n",
    "            list_outputs.append(voutputs)\n",
    "            list_labels.append(torch.argmax(vlabels, dim=1))\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "            # appending the val loss for the graph plotting\n",
    "            modified_attention_heads_val_loss.append(vloss.item())\n",
    "\n",
    "        voutputs = torch.cat(list_outputs, dim=0)\n",
    "        vlabels = torch.cat(list_labels).squeeze()\n",
    "        vacc = metric(voutputs, vlabels)\n",
    "        \n",
    "        # appending the val accuracy for plotting graph\n",
    "        modified_attention_heads_val_acc.append(vacc)\n",
    "\n",
    "        avg_vloss = running_vloss / (i+1)\n",
    "        print(\"Loss train {:.3f},  validation {:.3f},  val acc {:.3f}\".format(avg_loss, avg_vloss, vacc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humanlike-ocr",
   "language": "python",
   "name": "humanlike-ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
